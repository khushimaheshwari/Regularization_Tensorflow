{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Regularization_CNN_Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zTLfHaUP8wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbLfnah5P8wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7qDNsCyP8wM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "5f755f95-a0f0-48b2-a15c-2efdff8bdf76"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import  input_data\n",
        "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 14:29:31.251749 139729501616000 deprecation.py:323] From <ipython-input-3-27afc53753d9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0730 14:29:31.253098 139729501616000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0730 14:29:31.254861 139729501616000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0730 14:29:31.752139 139729501616000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0730 14:29:32.002633 139729501616000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0730 14:29:32.005130 139729501616000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0730 14:29:32.623369 139729501616000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9mwO5CxP8wP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4322bd6d-040a-4229-9ce0-b5e471055e23"
      },
      "source": [
        "mnist.train.images.shape,mnist.train.labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((55000, 784), (55000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJDO7wYzP8wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_width=28\n",
        "input_height=28\n",
        "input_channels=1\n",
        "input_pixels=784\n",
        "\n",
        "n_conv1=32\n",
        "n_conv2=64\n",
        "stride_conv1=1\n",
        "stride_conv2=1\n",
        "conv1_k=5\n",
        "conv2_k=5\n",
        "max_pool1_k=2\n",
        "max_pool2_k=2\n",
        "n_hidden=1024\n",
        "n_out=10\n",
        "\n",
        "input_size_to_hidden=(input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k))* n_conv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfHNzJ-9P8wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights={\n",
        "    'wc1':tf.Variable(tf.random_normal(shape=(conv1_k,conv1_k,input_channels, n_conv1))),  # weight matrix for layer 1\n",
        "    'wc2':tf.Variable(tf.random_normal(shape=(conv2_k,conv2_k,n_conv1, n_conv2))),    # weight matrix for layer 2\n",
        "   'wh1':tf.Variable(tf.random_normal(shape=(input_size_to_hidden, n_hidden))),    # weight matrix for layer 2'\n",
        "    'wo':tf.Variable(tf.random_normal(shape=(n_hidden,n_out))) # weight matrix for layer 3\n",
        "}\n",
        "biases={\n",
        "    'bc1':tf.Variable(tf.random_normal([n_conv1])),\n",
        "     'bc2':tf.Variable(tf.random_normal([n_conv2])),\n",
        "    'bh1':tf.Variable(tf.random_normal([n_hidden])),         # biases for layer 1\n",
        "    'bo':tf.Variable(tf.random_normal([n_out])),      # biases for layer 1\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kioUxO4VP8wX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv(x,weights,bias,strides=1):\n",
        "    out=tf.nn.conv2d(x,weights,padding=\"SAME\",strides=[1,strides,strides,1])\n",
        "    out=tf.nn.bias_add(out,bias)\n",
        "    out=tf.nn.relu(out)\n",
        "    return out\n",
        "\n",
        "def maxpooling(x,k=2):\n",
        "    return tf.nn.max_pool(x,padding=\"SAME\",ksize=[1,k,k,1],strides=[1,k,k,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaRBhyg5P8wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn(x,weights,biases,keep_prob):\n",
        "    x=tf.reshape(x,shape=[-1,input_width, input_height, input_channels])\n",
        "    conv1=conv(x,weights['wc1'],biases['bc1'],stride_conv1)\n",
        "    conv1_pool=maxpooling(conv1,max_pool1_k)\n",
        "    \n",
        "    conv2=conv(conv1_pool, weights['wc2'],biases['bc2'],stride_conv2)\n",
        "    conv2_pool=maxpooling(conv2,max_pool2_k)\n",
        "    \n",
        "    hidden_input=tf.reshape(conv2_pool,shape=[-1,input_size_to_hidden])\n",
        "    hidden_output_before_activation=tf.add(tf.matmul(hidden_input,weights['wh1']), biases['bh1'])\n",
        "    \n",
        "    hidden_output_before_dropout=tf.nn.relu(hidden_output_before_activation)\n",
        "    hidden_output=tf.nn.dropout( hidden_output_before_dropout, keep_prob)\n",
        "    \n",
        "    output=tf.add(tf.matmul(hidden_output,weights['wo']),biases['bo'])\n",
        "    return output\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSXqc5NeP8wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c6ae6aa8-ee50-4e8b-8bfb-74e5b5dc45b1"
      },
      "source": [
        "x=tf.placeholder('float',[None,input_pixels])      #since no. of input instance is different for training and testing\n",
        "y=tf.placeholder(tf.int32,[None,n_out])\n",
        "keep_prob=tf.placeholder('float')\n",
        "pred=cnn(x,weights,biases,keep_prob)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0730 14:29:33.005907 139729501616000 deprecation.py:506] From <ipython-input-8-9ab4005eebc2>:13: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWQ5XLGyP8wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "64b753c0-4d5d-49a0-9224-2e8c1ed25252"
      },
      "source": [
        "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y)) #logits is because of multiple classes \n",
        "\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "optimize=optimizer.minimize(cost)\n",
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "batch_size=100\n",
        "for i in range(25):\n",
        "    num_batches=mnist.train.num_examples//batch_size\n",
        "    total_cost=0\n",
        "    for j in range(num_batches):\n",
        "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
        "        c,_=sess.run([cost,optimize],feed_dict={x:batch_x,y:batch_y, keep_prob:0.8 })\n",
        "        total_cost+=c\n",
        "    print(total_cost)    \n",
        "    \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "787896.6421284676\n",
            "35576.514347583055\n",
            "20872.848658851868\n",
            "14903.333839154897\n",
            "11255.679214928474\n",
            "8660.02426001517\n",
            "8679.162090844879\n",
            "6713.049797238945\n",
            "6819.021234335009\n",
            "5557.916645219733\n",
            "4810.24178134071\n",
            "4709.388835262811\n",
            "2972.4738087332253\n",
            "3457.9532778168523\n",
            "3091.9847892526873\n",
            "3084.958458912325\n",
            "3173.997729080649\n",
            "2770.7447603702767\n",
            "2442.03072940404\n",
            "2492.9233363270773\n",
            "2383.473474850284\n",
            "2625.566243447038\n",
            "2155.0809841815935\n",
            "1592.7668598231346\n",
            "1604.33840451572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPhBi9rlP8wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5db6672a-230a-4242-d3a3-ddc62afad98f"
      },
      "source": [
        "predictions=tf.argmax(pred,1)\n",
        "true_labels=tf.argmax(y,1)\n",
        "correct_preds=tf.equal(predictions,true_labels)\n",
        "correct_ones,labels,correct_preds=sess.run([predictions, true_labels,correct_preds],feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1})\n",
        "correct_ones,labels,correct_preds"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([7, 2, 1, ..., 4, 5, 6]),\n",
              " array([7, 2, 1, ..., 4, 5, 6]),\n",
              " array([ True,  True,  True, ...,  True,  True,  True]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}